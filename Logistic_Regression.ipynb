{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn import cross_validation\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "% matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364171, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I did this on IBM cloud where file size limit was 256 MB. Hence I removed duplicates.\n",
    "# Also, the score has been turned into binary class- Positive and Negative\n",
    "\n",
    "con = sqlite3.connect(r\"final.sqlite\")\n",
    "filtered_data = pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "\"\"\", con)\n",
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    87729\n",
       "Negative    12271\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking first 100,000 points for analysis\n",
    "\n",
    "filtered_data = filtered_data.sort_values(by=['Time'])\n",
    "final = filtered_data[:100000]\n",
    "final.Score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kushalkul01/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "i=0;\n",
    "for sent in final['Text'].values:\n",
    "    if (len(re.findall('<.*?>', sent))):\n",
    "        #print(i)\n",
    "        #print(sent)\n",
    "        break;\n",
    "    i += 1;    \n",
    "\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "\n",
    "stop = set(stopwords.words('english')) #set of stopwords\n",
    "sno = SnowballStemmer('english') #initialising the snowball stemmer\n",
    "\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "all_positive_words=[] # store words from +ve reviews here\n",
    "all_negative_words=[] # store words from -ve reviews here.\n",
    "s=''\n",
    "for sent in final['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    #print(sent);\n",
    "    sent=cleanhtml(sent) # remove HTMl tags\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
    "                if(cleaned_words.lower() not in stop):\n",
    "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    if (final['Score'].values)[i] == 'Positive': \n",
    "                        all_positive_words.append(s) #list of all words used to describe positive reviews\n",
    "                    if(final['Score'].values)[i] == 'Negative':\n",
    "                        all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue \n",
    "    #print(filtered_sentence)\n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
    "    #print(\"***********************************************************************\")\n",
    "    \n",
    "    final_string.append(str1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final['CleanedText']=final_string #adding a column of CleanedText which displays the data after pre-processing of the review \n",
    "final['CleanedText']=final['CleanedText'].str.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y-vector is (100000,)\n"
     ]
    }
   ],
   "source": [
    "final = final.sort_values(by=['Time']) #Just to be double sure that dataframe is sorted according to time\n",
    "\n",
    "# Taking labels to make y-dimension\n",
    "labels=final['Score'].values\n",
    "\n",
    "# Checking the shape of labels\n",
    "print(\"Shape of y-vector is\",labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Taking initial 70% data as training data and remaining 30% as test data\n",
    "\n",
    "l = 0.7 * final.shape[0]\n",
    "X_train = final['CleanedText'][0:int(l)]\n",
    "X_test = final['CleanedText'][int(l):]\n",
    "y_train = labels[0:int(l)]\n",
    "y_test = labels[int(l):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Bag-of-Words Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# Making the bag of words model\n",
    "# Fitting the model on Training data and transforming the test data on the fitted model\n",
    "# This helps in taking care of data leakage\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer()\n",
    "X_train_bow = bow.fit_transform(X_train)\n",
    "X_test_bow = bow.transform(X_test)\n",
    "y_train_bow = y_train\n",
    "y_test_bow = y_test\n",
    "print(\"The type of count vectorizer \",type(X_train_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler(with_mean=False)\n",
    "X_train_bow = ss.fit_transform(X_train_bow)\n",
    "X_test_bow = ss.transform(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting 'Positive' and 'Negative' into True and False\n",
    "\n",
    "y_train_bow = y_train_bow=='Positive'\n",
    "y_test_bow = y_test_bow=='Positive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Grid Seach CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Using L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Optimal F-score: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Finding the best parameters using Grid Seach CV using 10-fold Cross-Validation in Logistic Regression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 1, 10**2, 10**4]}]\n",
    "gridmodel1 = GridSearchCV(LogisticRegression(penalty = 'l1'), tuned_parameters, scoring = 'f1', cv=2, n_jobs=-1)\n",
    "gridmodel1.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "print(gridmodel1.best_estimator_)\n",
    "print(\"Optimal F-score: {:.2f}\".format(gridmodel1.score(X_test_bow, y_test_bow)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Using L2 Regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Optimal F-score: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Finding the best parameters using Grid Seach CV using 10-fold Cross-Validation in Logistic Regression\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 1, 10**2, 10**4]}]\n",
    "gridmodel2 = GridSearchCV(LogisticRegression(penalty = 'l2'), tuned_parameters, scoring = 'f1', cv=2, n_jobs=-1)\n",
    "gridmodel2.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "print(gridmodel2.best_estimator_)\n",
    "print(\"Optimal F-score: {:.2f}\".format(gridmodel2.score(X_test_bow, y_test_bow)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Randomized Search CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 Using L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Optimal F-score: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Finding the best parameters using Random Seach CV\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_parameters = {'C': [10**-4,10**-3,10**-2,10**-1, 1, 10, 100, 1000]}\n",
    "randommodel1 = RandomizedSearchCV(LogisticRegression(penalty='l1'), random_parameters, scoring = 'f1', cv=2, n_iter=4, n_jobs=-1)\n",
    "randommodel1.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "print(randommodel1.best_estimator_)\n",
    "print(\"Optimal F-score: {:.2f}\".format(randommodel1.score(X_test_bow, y_test_bow)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Using L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Optimal F-score: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Finding the best parameters using Random Seach CV\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_parameters = {'C': [10**-5,10**-4,10**-3,10**-2,10**-1, 1, 10, 100, 1000]}\n",
    "randommodel2 = RandomizedSearchCV(LogisticRegression(penalty='l2'), random_parameters, scoring = 'f1', cv=2, n_iter=4, n_jobs=-1)\n",
    "randommodel2.fit(X_train_bow, y_train_bow)\n",
    "\n",
    "print(randommodel2.best_estimator_)\n",
    "print(\"Optimal F-score: {:.2f}\".format(randommodel2.score(X_test_bow, y_test_bow)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence out of all the techniques applied, best F-Score (0.95) was obtained. However, both models- Grid and Random gave exactly same results for L1 and L2 regularizer respectively.\n",
    "\n",
    "### 2.3 Fitting the best model and calculating different performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR for the model on test data is 0.96\n",
      "FPR for the model on test data is 0.42\n",
      "TNR for the model on test data is 0.58\n",
      "FNR for the model on test data is 0.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fitting the best model\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', C=0.01)\n",
    "lr.fit(X_train_bow, y_train_bow)\n",
    "y_pred_bow = lr.predict(X_test_bow)\n",
    "\n",
    "cm_bow=confusion_matrix(y_test_bow,y_pred_bow)\n",
    "print(\"Confusion Matrix:\")\n",
    "sns.heatmap(cm_bow, annot=True, fmt='d')\n",
    "plt.show()\n",
    "\n",
    "# calculating TPR, FPR, TNR, FNR\n",
    "\n",
    "tn, fp, fn, tp = cm_bow.ravel()\n",
    "\n",
    "tnr_bow = tn/(tn+fp)\n",
    "fpr_bow = fp/(tn+fp)\n",
    "fnr_bow = fn/(fn+tp)\n",
    "tpr_bow = tp/(fn+tp)\n",
    "\n",
    "print(\"TPR for the model on test data is {:.2f}\".format(tpr_bow))\n",
    "print(\"FPR for the model on test data is {:.2f}\".format(fpr_bow))\n",
    "print(\"TNR for the model on test data is {:.2f}\".format(tnr_bow))\n",
    "print(\"FNR for the model on test data is {:.2f}\\n\".format(fnr_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for the model on test data is 0.91\n",
      "Precision score for the model on test data is 0.94\n",
      "Recall score for the model on test data is 0.96\n",
      "F1 score for the model on test data is 0.95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculating precision and recall \n",
    "accuracy_bow = accuracy_score(y_test_bow , y_pred_bow)\n",
    "precision_bow = precision_score(y_test_bow , y_pred_bow)\n",
    "recall_bow = recall_score(y_test_bow , y_pred_bow)\n",
    "f1_bow = f1_score(y_test_bow , y_pred_bow)\n",
    "\n",
    "print(\"Accuracy score for the model on test data is {:.2f}\".format(accuracy_bow))\n",
    "print(\"Precision score for the model on test data is {:.2f}\".format(precision_bow))\n",
    "print(\"Recall score for the model on test data is {:.2f}\".format(recall_bow))\n",
    "print(\"F1 score for the model on test data is {:.2f}\\n\".format(f1_bow))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Checking sparsity with increasing value of lambda (decreasing C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.0001 ; non-zeros=23471\n",
      "lambda=0.001 ; non-zeros=23732\n",
      "lambda=0.01 ; non-zeros=18284\n",
      "lambda=0.1 ; non-zeros=14487\n",
      "lambda=1.0 ; non-zeros=12288\n",
      "lambda=10.0 ; non-zeros=9669\n",
      "lambda=100.0 ; non-zeros=3145\n",
      "lambda=1000.0 ; non-zeros=55\n",
      "lambda=10000.0 ; non-zeros=0\n"
     ]
    }
   ],
   "source": [
    "lambd = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "for i in lambd[::-1]:\n",
    "    lrr = LogisticRegression(penalty = 'l1', C = i)\n",
    "    lrr.fit(X_train_bow, y_train_bow)\n",
    "    print(\"lambda=\"+str(1/i)+\" ; non-zeros=\"+str(np.count_nonzero(lrr.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is clear, when the value of λ increases, the number of non-zeros decrease. This implies that when alpha goes up, the number of non-zeros go down and hence number of zeros go up.\n",
    "\n",
    "As λ reaches ten-thousand, all the values of coefficients approach zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Checking for Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l2', C=0.01)\n",
    "lr.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise= -0.1282136085523735\n"
     ]
    }
   ],
   "source": [
    "# Applying perturbation and checking if the coefficients differ too much\n",
    "# Will not add noise to zeros\n",
    "\n",
    "noise = np.random.normal(0 , 0.1 , 1)\n",
    "print(\"Noise= \"+str(noise[0]))\n",
    "X_train_bow.data = X_train_bow.data + noise[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the new model on the transformed data\n",
    "\n",
    "lr2 = LogisticRegression(penalty='l2', C=0.01)\n",
    "lr2.fit(X_train_bow, y_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features whose coefficients changed by more than 40% = 2790\n"
     ]
    }
   ],
   "source": [
    "# Calculating the percentage change between the old and new coefficients\n",
    "count=0\n",
    "for i in range(X_train_bow.shape[1]):\n",
    "    delta = abs((((lr.coef_[0][i] - lr2.coef_[0][i]) * 100))/ lr.coef_[0][i])\n",
    "    if delta>40:\n",
    "        count+=1\n",
    "        \n",
    "print(\"Number of features whose coefficients changed by more than 40% =\",count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence for most of the some features, the value of coefficients changed a lot. Hence features are multicollinear in nature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Words are:\n",
      " ['worst' 'disappoint' 'www' 'tast' 'aw' 'canida' 'context' 'unfortun'\n",
      " 'earth' 'terribl']\n",
      "\n",
      "Positive Words are:\n",
      " ['favorit' 'amaz' 'nice' 'addict' 'delici' 'good' 'perfect' 'love' 'best'\n",
      " 'great']\n"
     ]
    }
   ],
   "source": [
    "# Taking values for probabilities for BoW\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', C=0.1)\n",
    "lr.fit(X_train_bow, y_train_bow)\n",
    "prob_score = lr.coef_\n",
    "probs = prob_score.argsort() # Probabilities of y=1 in ascending order\n",
    "\n",
    "# Taking words with Maximum Probabilities for negative and positive labels\n",
    "\n",
    "neg_words = np.take(bow.get_feature_names(), probs[0][:10]) # Lowest probabilities of y=1\n",
    "pos_words = np.take(bow.get_feature_names(), probs[0][-10:]) # highest probabilities of y=1\n",
    "\n",
    "print(\"Negative Words are:\\n\" , neg_words, end='\\n\\n')\n",
    "print(\"Positive Words are:\\n\" , pos_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, the positive and negative words are clearly demarcated from the logistic regression\n",
    "\n",
    "# 3.0 TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing the right libraries\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# making tf-idf vector\n",
    "\n",
    "tf_idf_vect = TfidfVectorizer() # using ngram_range as (1,1) due to computation restrictions\n",
    "X_train_tf = tf_idf_vect.fit_transform(X_train)\n",
    "X_test_tf = tf_idf_vect.transform(X_test)\n",
    "y_train_tf = y_train\n",
    "y_test_tf = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting 'Positive' and 'Negative' into True and False\n",
    "\n",
    "y_train_tf = y_train_tf == 'Positive'\n",
    "y_test_tf = y_test_tf == 'Positive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Grid Seach CV for Optimal λ (C) and Penalty (among L1 and L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************\n",
      "\n",
      "Using L1 regularization-\n",
      "\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Optimal F-score: 0.96\n",
      "\n",
      "\n",
      "************************************************************************\n",
      "\n",
      "\n",
      "Using L2 regularization- \n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Optimal F-score: 0.95\n",
      "\n",
      "\n",
      "************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Finding the best parameters using Random Seach CV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tuned_parameters = {'C': [10**-4, 10**-2, 1, 10**2, 10**4]}\n",
    "                   \n",
    "gridmodel1 = GridSearchCV(LogisticRegression(penalty='l1'), tuned_parameters, scoring = 'f1', cv=2)\n",
    "gridmodel1.fit(X_train_tf, y_train_tf)\n",
    "\n",
    "gridmodel2 = GridSearchCV(LogisticRegression(penalty='l2'), tuned_parameters, scoring = 'f1', cv=2)\n",
    "gridmodel2.fit(X_train_tf, y_train_tf)\n",
    "\n",
    "print(\"************************************************************************\")\n",
    "print(\"\\nUsing L1 regularization-\\n\")\n",
    "print(gridmodel1.best_estimator_)\n",
    "print(\"\\nOptimal F-score: {:.2f}\".format(gridmodel1.score(X_test_tf, y_test_tf)))\n",
    "print('\\n')\n",
    "print(\"************************************************************************\")\n",
    "print('\\n')\n",
    "print(\"Using L2 regularization- \")\n",
    "print(gridmodel2.best_estimator_)\n",
    "print(\"Optimal F-score: {:.2f}\".format(gridmodel2.score(X_test_tf, y_test_tf)))\n",
    "print('\\n')\n",
    "print(\"************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Random Seach CV for Optimal λ (C) and Penalty (among L1 and L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************\n",
      "\n",
      "Using L1 regularization-\n",
      "\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Optimal F-score: 0.96\n",
      "\n",
      "\n",
      "************************************************************************\n",
      "\n",
      "\n",
      "Using L2 regularization- \n",
      "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Optimal F-score: 0.96\n",
      "\n",
      "\n",
      "************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Finding the best parameters using Random Seach CV\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_parameters = {'C': [10**-4, 10**-3, 10**-2, 0.1, 1, 10, 10**2, 10**3 , 10**4]}\n",
    "                   \n",
    "randommodel1 = RandomizedSearchCV(LogisticRegression(penalty='l1'), random_parameters, scoring = 'f1', cv=2, n_iter=4)\n",
    "randommodel1.fit(X_train_tf, y_train_tf)\n",
    "\n",
    "randommodel2 = RandomizedSearchCV(LogisticRegression(penalty='l2'), random_parameters, scoring = 'f1', cv=2, n_iter=4)\n",
    "randommodel2.fit(X_train_tf, y_train_tf)\n",
    "\n",
    "print(\"************************************************************************\")\n",
    "print(\"\\nUsing L1 regularization-\\n\")\n",
    "print(randommodel1.best_estimator_)\n",
    "print(\"\\nOptimal F-score: {:.2f}\".format(randommodel1.score(X_test_tf, y_test_tf)))\n",
    "print('\\n')\n",
    "print(\"************************************************************************\")\n",
    "print('\\n')\n",
    "print(\"Using L2 regularization- \")\n",
    "print(randommodel2.best_estimator_)\n",
    "print(\"\\nOptimal F-score: {:.2f}\".format(randommodel2.score(X_test_tf, y_test_tf)))\n",
    "print('\\n')\n",
    "print(\"************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost similar results for L1 and exactly same for L2.\n",
    "So, to get best model (highest F1 score), we will use L2 regularization with C=1\n",
    "\n",
    "### 3.3 Fitting the best model and calculating different performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR for the model on test data is 0.97\n",
      "FPR for the model on test data is 0.40\n",
      "TNR for the model on test data is 0.60\n",
      "FNR for the model on test data is 0.03\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fitting the best model\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', C=10)\n",
    "lr.fit(X_train_tf, y_train_tf)\n",
    "y_pred_tf = lr.predict(X_test_tf)\n",
    "\n",
    "# Generating the confusion matrix\n",
    "cm_tf = confusion_matrix(y_test_tf , y_pred_tf)\n",
    "print(\"Confusion Matrix:\")\n",
    "sns.heatmap(cm_tf, annot=True, fmt='d')\n",
    "plt.show()\n",
    "\n",
    "# calculating TPR, FPR, TNR, FNR\n",
    "\n",
    "tn, fp, fn, tp = cm_tf.ravel()\n",
    "\n",
    "tnr_tf = tn/(tn+fp)\n",
    "fpr_tf = fp/(tn+fp)\n",
    "fnr_tf = fn/(fn+tp)\n",
    "tpr_tf = tp/(fn+tp)\n",
    "\n",
    "print(\"TPR for the model on test data is {:.2f}\".format(tpr_tf))\n",
    "print(\"FPR for the model on test data is {:.2f}\".format(fpr_tf))\n",
    "print(\"TNR for the model on test data is {:.2f}\".format(tnr_tf))\n",
    "print(\"FNR for the model on test data is {:.2f}\\n\".format(fnr_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for the model on test data is 0.92\n",
      "Precision score for the model on test data is 0.94\n",
      "Recall score for the model on test data is 0.97\n",
      "F1 score for the model on test data is 0.96\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculating accuracy, precision and recall \n",
    "\n",
    "accuracy_tf = accuracy_score(y_test_tf , y_pred_tf)\n",
    "precision_tf = precision_score(y_test_tf , y_pred_tf)\n",
    "recall_tf = recall_score(y_test_tf , y_pred_tf)\n",
    "f1_tf = f1_score(y_test_tf , y_pred_tf)\n",
    "\n",
    "print(\"Accuracy score for the model on test data is {:.2f}\".format(accuracy_tf))\n",
    "print(\"Precision score for the model on test data is {:.2f}\".format(precision_tf))\n",
    "print(\"Recall score for the model on test data is {:.2f}\".format(recall_tf))\n",
    "print(\"F1 score for the model on test data is {:.2f}\\n\".format(f1_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Checking sparsity with increasing value of  λ (decreasing C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.0001 ; non-zeros=14552\n",
      "lambda=0.001 ; non-zeros=13174\n",
      "lambda=0.01 ; non-zeros=11208\n",
      "lambda=0.1 ; non-zeros=6811\n",
      "lambda=1.0 ; non-zeros=1268\n",
      "lambda=10.0 ; non-zeros=185\n",
      "lambda=100.0 ; non-zeros=3\n",
      "lambda=1000.0 ; non-zeros=0\n",
      "lambda=10000.0 ; non-zeros=0\n"
     ]
    }
   ],
   "source": [
    "lambd = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "for i in lambd[::-1]:\n",
    "    lrr = LogisticRegression(penalty = 'l1', C = i)\n",
    "    lrr.fit(X_train_tf, y_train_tf)\n",
    "    print(\"lambda=\"+str(1/i)+\" ; non-zeros=\"+str(np.count_nonzero(lrr.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is clear, when the value of λ increases, the number of non-zeros decrease. This implies that when alpha goes up, the number of non-zeros go down and hence number of zeros go up.\n",
    "\n",
    "As λ reaches 1000, all the values of coefficients approach zero.\n",
    "\n",
    "### 3.5 Checking for Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noise= -0.15880593569504242\n"
     ]
    }
   ],
   "source": [
    "# Applying perturbation and checking if the coefficients differ too much\n",
    "\n",
    "noise = np.random.normal(0 , 0.1 , 1)\n",
    "print(\"Noise= \"+str(noise[0]))\n",
    "X_train_tf.data = X_train_tf.data + noise[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the new model on the transformed data\n",
    "\n",
    "lr2 = LogisticRegression(penalty='l2', C=1)\n",
    "lr2.fit(X_train_tf, y_train_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features whose coefficients changed by more than 40% = 28767\n"
     ]
    }
   ],
   "source": [
    "# Calculating the percentage change between the old and new coefficients\n",
    "\n",
    "# Calculating the percentage change between the old and new coefficients\n",
    "count=0\n",
    "for i in range(X_train_tf.shape[1]):\n",
    "    delta = abs((((lr.coef_[0][i] - lr2.coef_[0][i]) * 100))/ lr.coef_[0][i])\n",
    "    if delta>40:\n",
    "        count+=1\n",
    "        \n",
    "print(\"Number of features whose coefficients changed by more than 40% =\",count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percentage change in the values of coefficients is quite small, hence we can conclude that features are quite independent of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Words are:\n",
      " ['worst' 'disappoint' 'terribl' 'aw' 'bland' 'threw' 'horribl' 'unfortun'\n",
      " 'tasteless' 'ugh']\n",
      "\n",
      "Positive Words are:\n",
      " ['nice' 'awesom' 'addict' 'amaz' 'excel' 'love' 'delici' 'perfect' 'best'\n",
      " 'great']\n"
     ]
    }
   ],
   "source": [
    "# Taking values for probabilities for BoW\n",
    "\n",
    "prob_score = lr.coef_\n",
    "probs = prob_score.argsort()\n",
    "\n",
    "# Taking words with Maximum Probabilities for negative and positive labels\n",
    "neg_words = np.take(tf_idf_vect.get_feature_names(), probs[0][:10])\n",
    "pos_words = np.take(tf_idf_vect.get_feature_names(), probs[0][-10:])\n",
    "\n",
    "print(\"Negative Words are:\\n\" , neg_words, end='\\n\\n')\n",
    "print(\"Positive Words are:\\n\" , pos_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i=0\n",
    "list_of_sent=[]\n",
    "for sent in X_train:\n",
    "    list_of_sent.append(sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like\n"
     ]
    }
   ],
   "source": [
    "# min_count = 5 considers only words that occured atleast 5 times\n",
    "w2v_model=Word2Vec(list_of_sent,min_count=5,size=50, workers=4)\n",
    "w2v_words = list(w2v_model.wv.vocab)\n",
    "count_vect_feat = bow.get_feature_names() # list of words in the BoW\n",
    "print(count_vect_feat[count_vect_feat.index('like')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Average Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "sent_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in list_of_sent: # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        sent_vec /= cnt_words\n",
    "    sent_vectors.append(sent_vec)\n",
    "print(len(sent_vectors))\n",
    "print(len(sent_vectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "list_of_sent_tst=[]\n",
    "for sent in X_test:\n",
    "    list_of_sent_tst.append(sent.split())\n",
    "    \n",
    "sent_vectors_test = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in list_of_sent_tst: # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        sent_vec /= cnt_words\n",
    "    sent_vectors_test.append(sent_vec)\n",
    "print(len(sent_vectors_test))\n",
    "print(len(sent_vectors_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_train : 70000\n",
      "Length of X_test : 30000\n"
     ]
    }
   ],
   "source": [
    "X_train_avg = sent_vectors\n",
    "X_test_avg = sent_vectors_test\n",
    "y_train_avg = y_train\n",
    "y_test_avg = y_test\n",
    "\n",
    "print(\"Length of X_train :\",len(X_train_avg))\n",
    "print(\"Length of X_test :\",len(X_test_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting 'Positive' and 'Negative' into True and False\n",
    "\n",
    "y_train_avg = y_train_avg == 'Positive'\n",
    "y_test_avg = y_test_avg == 'Positive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Grid Seach CV for Optimal λ (C) and Penalty (among L1 and L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************\n",
      "\n",
      "Using L1 regularization-\n",
      "\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Optimal F-score: 0.94\n",
      "\n",
      "\n",
      "************************************************************************\n",
      "\n",
      "\n",
      "Using L2 regularization-\n",
      "\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Optimal F-score: 0.94\n",
      "\n",
      "\n",
      "************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Finding the best parameters using Random Seach CV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tuned_parameters = {'C': [10**-4, 10**-2, 1, 10**2, 10**4]}\n",
    "                   \n",
    "gridmodel1 = GridSearchCV(LogisticRegression(penalty='l1'), tuned_parameters, scoring = 'f1', cv=2)\n",
    "gridmodel1.fit(X_train_avg, y_train_avg)\n",
    "\n",
    "gridmodel2 = GridSearchCV(LogisticRegression(penalty='l2'), tuned_parameters, scoring = 'f1', cv=2)\n",
    "gridmodel2.fit(X_train_avg, y_train_avg)\n",
    "\n",
    "print(\"************************************************************************\")\n",
    "print(\"\\nUsing L1 regularization-\\n\")\n",
    "print(gridmodel1.best_estimator_)\n",
    "print(\"\\nOptimal F-score: {:.2f}\".format(gridmodel1.score(X_test_avg, y_test_avg)))\n",
    "print('\\n')\n",
    "print(\"************************************************************************\")\n",
    "print('\\n')\n",
    "print(\"Using L2 regularization-\\n\")\n",
    "print(gridmodel2.best_estimator_)\n",
    "print(\"Optimal F-score: {:.2f}\".format(gridmodel2.score(X_test_avg, y_test_avg)))\n",
    "print('\\n')\n",
    "print(\"************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Random Seach CV for Optimal λ (C) and Penalty (among L1 and L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************\n",
      "\n",
      "Using L1 regularization-\n",
      "\n",
      "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Optimal F-score: 0.94\n",
      "\n",
      "\n",
      "************************************************************************\n",
      "\n",
      "\n",
      "Using L2 regularization- \n",
      "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Optimal F-score: 0.94\n",
      "\n",
      "\n",
      "************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Finding the best parameters using Random Seach CV\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_parameters = {'C': [10**-4, 10**-3, 10**-2, 0.1, 1, 10, 10**2, 10**3 , 10**4]}\n",
    "                   \n",
    "randommodel1 = RandomizedSearchCV(LogisticRegression(penalty='l1'), random_parameters, scoring = 'f1', cv=2, n_iter=4)\n",
    "randommodel1.fit(X_train_avg, y_train_avg)\n",
    "\n",
    "randommodel2 = RandomizedSearchCV(LogisticRegression(penalty='l2'), random_parameters, scoring = 'f1', cv=2, n_iter=4)\n",
    "randommodel2.fit(X_train_avg, y_train_avg)\n",
    "\n",
    "print(\"************************************************************************\")\n",
    "print(\"\\nUsing L1 regularization-\\n\")\n",
    "print(randommodel1.best_estimator_)\n",
    "print(\"\\nOptimal F-score: {:.2f}\".format(randommodel1.score(X_test_avg, y_test_avg)))\n",
    "print('\\n')\n",
    "print(\"************************************************************************\")\n",
    "print('\\n')\n",
    "print(\"Using L2 regularization- \")\n",
    "print(randommodel2.best_estimator_)\n",
    "print(\"\\nOptimal F-score: {:.2f}\".format(randommodel2.score(X_test_avg, y_test_avg)))\n",
    "print('\\n')\n",
    "print(\"************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we got almost similar results for L1 and exactly same for L2.\n",
    "C=10000 and C=1000 give almost similar result for L2 regularization\n",
    "So, to get best model (highest F1 score), we will use L1 regularization with C=10000\n",
    "\n",
    "### 4.1.3 Fitting the best model and calculating different performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR for the model on test data is 0.98\n",
      "FPR for the model on test data is 0.64\n",
      "TNR for the model on test data is 0.36\n",
      "FNR for the model on test data is 0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fitting the best model\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', C=1)\n",
    "lr.fit(X_train_avg, y_train_avg)\n",
    "y_pred_avg = lr.predict(X_test_avg)\n",
    "\n",
    "cm_avg = confusion_matrix(y_test_avg , y_pred_avg)\n",
    "print(\"Confusion Matrix:\")\n",
    "sns.heatmap(cm_avg, annot=True, fmt='d')\n",
    "plt.show()\n",
    "\n",
    "# calculating TPR, FPR, TNR, FNR\n",
    "\n",
    "tn, fp, fn, tp = cm_avg.ravel()\n",
    "\n",
    "tnr_avg = tn/(tn+fp)\n",
    "fpr_avg = fp/(tn+fp)\n",
    "fnr_avg = fn/(fn+tp)\n",
    "tpr_avg = tp/(fn+tp)\n",
    "\n",
    "print(\"TPR for the model on test data is {:.2f}\".format(tpr_avg))\n",
    "print(\"FPR for the model on test data is {:.2f}\".format(fpr_avg))\n",
    "print(\"TNR for the model on test data is {:.2f}\".format(tnr_avg))\n",
    "print(\"FNR for the model on test data is {:.2f}\\n\".format(fnr_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for the model on test data is 0.89\n",
      "Precision score for the model on test data is 0.91\n",
      "Recall score for the model on test data is 0.98\n",
      "F1 score for the model on test data is 0.94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculating accuracy, precision and recall \n",
    "\n",
    "accuracy_avg = accuracy_score(y_test_avg , y_pred_avg)\n",
    "precision_avg = precision_score(y_test_avg , y_pred_avg)\n",
    "recall_avg = recall_score(y_test_avg , y_pred_avg)\n",
    "f1_avg = f1_score(y_test_avg , y_pred_avg)\n",
    "\n",
    "print(\"Accuracy score for the model on test data is {:.2f}\".format(accuracy_avg))\n",
    "print(\"Precision score for the model on test data is {:.2f}\".format(precision_avg))\n",
    "print(\"Recall score for the model on test data is {:.2f}\".format(recall_avg))\n",
    "print(\"F1 score for the model on test data is {:.2f}\\n\".format(f1_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 Checking sparsity with increasing value of  λ (decreasing C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.0001 ; non-zeros=50\n",
      "lambda=0.001 ; non-zeros=50\n",
      "lambda=0.01 ; non-zeros=50\n",
      "lambda=0.1 ; non-zeros=50\n",
      "lambda=1.0 ; non-zeros=48\n",
      "lambda=10.0 ; non-zeros=48\n",
      "lambda=100.0 ; non-zeros=30\n",
      "lambda=1000.0 ; non-zeros=8\n",
      "lambda=10000.0 ; non-zeros=0\n"
     ]
    }
   ],
   "source": [
    "lambd = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "for i in lambd[::-1]:\n",
    "    lrr = LogisticRegression(penalty = 'l1', C = i)\n",
    "    lrr.fit(X_train_avg, y_train_avg)\n",
    "    print(\"lambda=\"+str(1/i)+\" ; non-zeros=\"+str(np.count_nonzero(lrr.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't check for multicollinearity for this vectorization technique as we don't have a single feature corresponding to a particular word. What we can do is just to extract most important features in the form of list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Words are:\n",
      " [-0.35828592 -0.00234891 -0.53356032  0.40707522 -0.40661463  0.63081045\n",
      " -0.05944975  0.35367625  0.06797562 -0.34554349]\n",
      "\n",
      "Positive Words are:\n",
      " [ 0.26721088  0.25417123 -0.08651268  0.79004333 -0.16602407  0.26591486\n",
      "  0.22550936 -0.36188176  0.54934199  0.30923101]\n"
     ]
    }
   ],
   "source": [
    "# Taking values for probabilities for Average-W2V\n",
    "\n",
    "prob_score = lr.coef_\n",
    "\n",
    "probs = prob_score.argsort()\n",
    "\n",
    "# Taking words with Maximum Probabilities for negative and positive labels\n",
    "neg_words = np.take(sent_vectors, probs[0][:10])\n",
    "pos_words = np.take(sent_vectors, probs[0][-10:])\n",
    "\n",
    "print(\"Negative Words are:\\n\" , neg_words, end='\\n\\n')\n",
    "print(\"Positive Words are:\\n\" , pos_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 TF-IDF Weighted Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF weighted Word2Vec\n",
    "tfidf_feat = tf_idf_vect.get_feature_names() # tfidf words/col-names\n",
    "\n",
    "tfidf_sent_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "for sent in list_of_sent: # for each review/sentence \n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "            # obtain the tf_idfidf of a word in a sentence/review\n",
    "            tf_idf = X_train_tf[row, tfidf_feat.index(word)]\n",
    "            sent_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "    if weight_sum != 0:\n",
    "        sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors.append(sent_vec)\n",
    "    row += 1\n",
    "    \n",
    "print(len(tfidf_sent_vectors))\n",
    "print(len(tfidf_sent_vectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "list_of_sent_tst=[]\n",
    "for sent in X_test:\n",
    "    list_of_sent_tst.append(sent.split())\n",
    "\n",
    "tfidf_sent_vectors_tst=[]\n",
    "row=0\n",
    "for sent in list_of_sent_tst: # for each review/sentence \n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "            # obtain the tf_idfidf of a word in a sentence/review\n",
    "            tf_idf = X_test_tf[row, tfidf_feat.index(word)]\n",
    "            sent_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "    if weight_sum != 0:\n",
    "        sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors_tst.append(sent_vec)\n",
    "    row += 1\n",
    "    \n",
    "print(len(tfidf_sent_vectors_tst))\n",
    "print(len(tfidf_sent_vectors_tst[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X_train : 70000\n",
      "Length of X_test : 30000\n"
     ]
    }
   ],
   "source": [
    "X_train_w2v = tfidf_sent_vectors\n",
    "X_test_w2v = tfidf_sent_vectors_tst\n",
    "y_train_w2v = y_train\n",
    "y_test_w2v = y_test\n",
    "\n",
    "print(\"Length of X_train :\",len(X_train_w2v))\n",
    "print(\"Length of X_test :\",len(X_test_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting 'Positive' and 'Negative' into True and False\n",
    "\n",
    "y_train_w2v = y_train_w2v == 'Positive'\n",
    "y_test_w2v = y_test_w2v == 'Positive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Grid Seach CV for Optimal λ (C) and Penalty (among L1 and L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************\n",
      "\n",
      "Using L1 regularization-\n",
      "\n",
      "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Optimal F-score: 0.94\n",
      "\n",
      "\n",
      "************************************************************************\n",
      "\n",
      "\n",
      "Using L2 regularization-\n",
      "\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Optimal F-score: 0.94\n",
      "\n",
      "\n",
      "************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Finding the best parameters using Random Seach CV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tuned_parameters = {'C': [10**-4, 10**-2, 1, 10**2, 10**4]}\n",
    "                   \n",
    "gridmodel1 = GridSearchCV(LogisticRegression(penalty='l1'), tuned_parameters, scoring = 'f1', cv=2)\n",
    "gridmodel1.fit(X_train_w2v, y_train_w2v)\n",
    "\n",
    "gridmodel2 = GridSearchCV(LogisticRegression(penalty='l2'), tuned_parameters, scoring = 'f1', cv=2)\n",
    "gridmodel2.fit(X_train_w2v, y_train_w2v)\n",
    "\n",
    "print(\"************************************************************************\")\n",
    "print(\"\\nUsing L1 regularization-\\n\")\n",
    "print(gridmodel1.best_estimator_)\n",
    "print(\"\\nOptimal F-score: {:.2f}\".format(gridmodel1.score(X_test_w2v, y_test_w2v)))\n",
    "print('\\n')\n",
    "print(\"************************************************************************\")\n",
    "print('\\n')\n",
    "print(\"Using L2 regularization-\\n\")\n",
    "print(gridmodel2.best_estimator_)\n",
    "print(\"Optimal F-score: {:.2f}\".format(gridmodel2.score(X_test_w2v, y_test_w2v)))\n",
    "print('\\n')\n",
    "print(\"************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Random Seach CV for Optimal λ (C) and Penalty (among L1 and L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************************\n",
      "\n",
      "Using L1 regularization-\n",
      "\n",
      "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Optimal F-score: 0.94\n",
      "\n",
      "\n",
      "************************************************************************\n",
      "\n",
      "\n",
      "Using L2 regularization- \n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Optimal F-score: 0.94\n",
      "\n",
      "\n",
      "************************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Finding the best parameters using Random Seach CV\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_parameters = {'C': [10**-4, 10**-3, 10**-2, 0.1, 1, 10, 10**2, 10**3 , 10**4]}\n",
    "                   \n",
    "randommodel1 = RandomizedSearchCV(LogisticRegression(penalty='l1'), random_parameters, scoring = 'f1', cv=2, n_iter=4)\n",
    "randommodel1.fit(X_train_w2v, y_train_w2v)\n",
    "\n",
    "randommodel2 = RandomizedSearchCV(LogisticRegression(penalty='l2'), random_parameters, scoring = 'f1', cv=2, n_iter=4)\n",
    "randommodel2.fit(X_train_w2v, y_train_w2v)\n",
    "\n",
    "print(\"************************************************************************\")\n",
    "print(\"\\nUsing L1 regularization-\\n\")\n",
    "print(randommodel1.best_estimator_)\n",
    "print(\"\\nOptimal F-score: {:.2f}\".format(randommodel1.score(X_test_w2v, y_test_w2v)))\n",
    "print('\\n')\n",
    "print(\"************************************************************************\")\n",
    "print('\\n')\n",
    "print(\"Using L2 regularization- \")\n",
    "print(randommodel2.best_estimator_)\n",
    "print(\"\\nOptimal F-score: {:.2f}\".format(randommodel2.score(X_test_w2v, y_test_w2v)))\n",
    "print('\\n')\n",
    "print(\"************************************************************************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we got exactly the same value of F-Score everytime, both for L1 and L2 regularization. We will take optimal model as L2 regularization for C=10000\n",
    "\n",
    "### 4.2.3 Fitting the best model and calculating different performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPR for the model on test data is 0.98\n",
      "FPR for the model on test data is 0.73\n",
      "TNR for the model on test data is 0.27\n",
      "FNR for the model on test data is 0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fitting the best model\n",
    "\n",
    "lr = LogisticRegression(penalty='l2', C=1)\n",
    "lr.fit(X_train_w2v, y_train_w2v)\n",
    "y_pred_w2v = lr.predict(X_test_w2v)\n",
    "\n",
    "# Generating the confusion matrix\n",
    "cm_w2v = confusion_matrix(y_test_w2v , y_pred_w2v)\n",
    "print(\"Confusion Matrix:\")\n",
    "sns.heatmap(cm_w2v, annot=True, fmt='d')\n",
    "plt.show()\n",
    "\n",
    "# calculating TPR, FPR, TNR, FNR\n",
    "\n",
    "tn, fp, fn, tp = cm_w2v.ravel()\n",
    "\n",
    "tnr_w2v = tn/(tn+fp)\n",
    "fpr_w2v = fp/(tn+fp)\n",
    "fnr_w2v = fn/(fn+tp)\n",
    "tpr_w2v = tp/(fn+tp)\n",
    "\n",
    "print(\"TPR for the model on test data is {:.2f}\".format(tpr_w2v))\n",
    "print(\"FPR for the model on test data is {:.2f}\".format(fpr_w2v))\n",
    "print(\"TNR for the model on test data is {:.2f}\".format(tnr_w2v))\n",
    "print(\"FNR for the model on test data is {:.2f}\\n\".format(fnr_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for the model on test data is 0.88\n",
      "Precision score for the model on test data is 0.90\n",
      "Recall score for the model on test data is 0.98\n",
      "F1 score for the model on test data is 0.94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculating accuracy, precision and recall \n",
    "\n",
    "accuracy_w2v = accuracy_score(y_test_w2v , y_pred_w2v)\n",
    "precision_w2v = precision_score(y_test_w2v , y_pred_w2v)\n",
    "recall_w2v = recall_score(y_test_w2v , y_pred_w2v)\n",
    "f1_w2v = f1_score(y_test_w2v , y_pred_w2v)\n",
    "\n",
    "print(\"Accuracy score for the model on test data is {:.2f}\".format(accuracy_w2v))\n",
    "print(\"Precision score for the model on test data is {:.2f}\".format(precision_w2v))\n",
    "print(\"Recall score for the model on test data is {:.2f}\".format(recall_w2v))\n",
    "print(\"F1 score for the model on test data is {:.2f}\\n\".format(f1_w2v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4 Checking for sparsity with increasing value of  λ (decreasing C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda=0.0001 ; non-zeros=50\n",
      "lambda=0.001 ; non-zeros=50\n",
      "lambda=0.01 ; non-zeros=50\n",
      "lambda=0.1 ; non-zeros=50\n",
      "lambda=1.0 ; non-zeros=50\n",
      "lambda=10.0 ; non-zeros=49\n",
      "lambda=100.0 ; non-zeros=34\n",
      "lambda=1000.0 ; non-zeros=9\n",
      "lambda=10000.0 ; non-zeros=0\n"
     ]
    }
   ],
   "source": [
    "lambd = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "for i in lambd[::-1]:\n",
    "    lrr = LogisticRegression(penalty = 'l1', C = i)\n",
    "    lrr.fit(X_train_w2v, y_train_w2v)\n",
    "    print(\"lambda=\"+str(1/i)+\" ; non-zeros=\"+str(np.count_nonzero(lrr.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we can't check for multicollinearity for this vectorization technique as we don't have any feature corresponding to a particular word.  What we can do is just to extract most important features in the form of list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Words are:\n",
      " [-0.16725518  0.47582129 -0.0032757   0.70867107  0.34610551  0.05484068\n",
      " -0.71122109  0.13882007 -1.10426409 -1.70038425]\n",
      "\n",
      "Positive Words are:\n",
      " [-0.86806124 -0.03538375  0.03252355  1.52272252  0.19294682 -0.48993716\n",
      "  0.28793287  0.72952546  0.43488519 -0.54336549]\n"
     ]
    }
   ],
   "source": [
    "# Taking values for probabilities for Average-W2V\n",
    "\n",
    "prob_score = lr.predict_log_proba(X_train_w2v)\n",
    "\n",
    "neg_bow = prob_score[:,0].argsort()\n",
    "pos_bow = prob_score[:,1].argsort()\n",
    "\n",
    "# Taking words with Maximum Probabilities for negative and positive labels\n",
    "neg_words = np.take(tfidf_sent_vectors, neg_bow[-10:])\n",
    "pos_words = np.take(tfidf_sent_vectors, pos_bow[-10:])\n",
    "\n",
    "print(\"Negative Words are:\\n\" , neg_words, end='\\n\\n')\n",
    "print(\"Positive Words are:\\n\" , pos_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression was successfully applied on all the text-processing techniques.\n",
    "\n",
    "In order to accomplish this task, 4 types of Text processing techniques were applied. First the optimal value of lambda was estimated using grid-search and then the model was fit using the value of optimal lambda.\n",
    "\n",
    "Post successful fitting of the model, the polarity (labels) on the test dataset was estimated using the model and was checked against the true polarity. Based on this, Accuracy, Precision-Score, Recall Score and F1-Score were calculated.\n",
    "\n",
    "The values of all the parameters are tabulated in the following table-\n",
    "\n",
    "\n",
    "\n",
    "<html>\n",
    "<head>\n",
    "\n",
    "<style>\n",
    "table {\n",
    "    font-family: arial, sans-serif;\n",
    "    border-collapse: collapse;\n",
    "    width: 100%;\n",
    "}\n",
    "\n",
    "td, th {\n",
    "    border: 1px solid #dddddd;\n",
    "    text-align: left;\n",
    "    padding: 8px;\n",
    "}\n",
    "    \n",
    "tr:nth-child(even) {\n",
    "    background-color: #dddddd;\n",
    "}\n",
    "</style>\n",
    "</head>\n",
    "<body>\n",
    "\n",
    "<h2>Table 5.1: Values of different parameters with Model</h2>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Model</th>\n",
    "    <th>Cross-Validation Technique</th>\n",
    "    <th>Regularization</th>\n",
    "    <th>Best C</th>\n",
    "    <th>Best λ=(1/C)</th>\n",
    "    <th>F1 Score</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Bag-of-Words</td>\n",
    "    <td>GridSearchCV</td>\n",
    "    <td>L1</td>\n",
    "    <td>0.01</td>\n",
    "    <td>100</td>\n",
    "    <td>0.95</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Bag-of-Words</td>\n",
    "    <td>GridSearchCV</td>\n",
    "    <td>L2</td>\n",
    "    <td>0.01</td>\n",
    "    <td>100</td>\n",
    "    <td>0.95</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>Bag-of-Words</td>\n",
    "    <td>RandomSearchCV</td>\n",
    "    <td>L1</td>\n",
    "    <td>1</td>\n",
    "    <td>1</td>\n",
    "    <td>0.93</td>\n",
    "   </tr>\n",
    "  <tr>\n",
    "      <td>Bag-of-Words</td>\n",
    "    <td>RandomSearchCV</td>\n",
    "    <td>L2</td>\n",
    "    <td>0.1</td>\n",
    "    <td>10</td>\n",
    "    <td>0.94</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>TF-IDF</td>\n",
    "    <td>GridSearchCV</td>\n",
    "    <td>L1</td>\n",
    "    <td>100</td>\n",
    "    <td>0.01</td>\n",
    "    <td>0.95</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>TF-IDF</td>\n",
    "    <td>GridSearchCV</td>\n",
    "    <td>L2</td>\n",
    "    <td>0.01</td>\n",
    "    <td>100</td>\n",
    "    <td>0.95</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>TF-IDF</td>\n",
    "    <td>RandomSearchCV</td>\n",
    "    <td>L1</td>\n",
    "    <td>1</td>\n",
    "    <td>1</td>\n",
    "    <td>0.93</td>\n",
    "   </tr>\n",
    "  <tr>\n",
    "      <td>TF-IDF</td>\n",
    "    <td>RandomSearchCV</td>\n",
    "    <td>L2</td>\n",
    "    <td>100</td>\n",
    "    <td>0.01</td>\n",
    "    <td>0.94</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Average W2V</td>\n",
    "    <td>GridSearchCV</td>\n",
    "    <td>L1</td>\n",
    "    <td>1</td>\n",
    "    <td>1</td>\n",
    "    <td>0.96</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>Average W2V</td>\n",
    "    <td>GridSearchCV</td>\n",
    "    <td>L2</td>\n",
    "    <td>1</td>\n",
    "    <td>1</td>\n",
    "    <td>0.96</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Average W2V</td>\n",
    "    <td>RandomSearchCV</td>\n",
    "    <td>L1</td>\n",
    "    <td>1</td>\n",
    "    <td>1</td>\n",
    "    <td>0.96</td>\n",
    "   </tr>\n",
    "  <tr>\n",
    "      <td>Average W2V</td>\n",
    "    <td>RandomSearchCV</td>\n",
    "    <td>L2</td>\n",
    "    <td>10</td>\n",
    "    <td>0.1</td>\n",
    "    <td>0.96</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Weighted W2V</td>\n",
    "    <td>GridSearchCV</td>\n",
    "    <td>L1</td>\n",
    "    <td>100</td>\n",
    "    <td>0.01</td>\n",
    "    <td>0.94</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>Weighted W2V</td>\n",
    "    <td>GridSearchCV</td>\n",
    "    <td>L2</td>\n",
    "    <td>1</td>\n",
    "    <td>1</td>\n",
    "    <td>0.94</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "      <td>Weighted W2V</td>\n",
    "      <td>RandomSearchCV</td>\n",
    "    <td>L1</td>\n",
    "    <td>10</td>\n",
    "    <td>0.1</td>\n",
    "    <td>0.94</td>\n",
    "   </tr>\n",
    "  <tr>\n",
    "      <td>Weighted W2V</td>\n",
    "      <td>RandomSearchCV</td>\n",
    "    <td>L2</td>\n",
    "    <td>10</td>\n",
    "    <td>0.1</td>\n",
    "    <td>0.94</td>\n",
    "  </tr> \n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<h2>Table 5.2: Test Metrics</h2>\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Model</th>\n",
    "    <th>λ=(1/C)</th>\n",
    "    <th>Penalty</th>\n",
    "    <th>Test Accuracy</th>\n",
    "    <th>Precision Score</th>\n",
    "    <th>Recall Score</th>\n",
    "    <th>F1 Score</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Bag-of-Words</td>\n",
    "    <td>100</td>\n",
    "    <td>L2</td>\n",
    "    <td>91 %</td>\n",
    "    <td>0.94</td>\n",
    "    <td>0.95</td>\n",
    "    <td>0.96</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>TF-IDF</td>\n",
    "    <td>0.1</td>\n",
    "    <td>L2</td>\n",
    "    <td>92 %</td>\n",
    "    <td>0.94</td>\n",
    "    <td>0.97</td>\n",
    "    <td>0.96</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Average W2V</td>\n",
    "    <td>1</td>\n",
    "    <td>L1</td>\n",
    "    <td>89 %</td>\n",
    "    <td>0.91</td>\n",
    "    <td>0.98</td>\n",
    "    <td>0.94</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Weighted W2V</td>\n",
    "    <td>1</td>\n",
    "    <td>L2</td>\n",
    "    <td>88 %</td>\n",
    "    <td>0.90</td>\n",
    "    <td>0.98</td>\n",
    "    <td>0.94</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "</body>\n",
    "</html>\n",
    "\n",
    "So, from the table data we can conclude that Grid-Search and Random-Search result in almost similar outcomes. \n",
    "\n",
    "Also, the sparsity increases (non-zeros decrease) with increasing values of λ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
